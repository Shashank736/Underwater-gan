{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import numpy\n",
    "import math\n",
    "import matplotlib.pyplot\n",
    "from enum import Enum, auto\n",
    "from torch.utils.data import DataLoader\n",
    "from nets import pix2pix\n",
    "from torchvision import transforms\n",
    "from ops.datasets import UganTrainingDataset, UganInferenceDataset, ToTensor\n",
    "from ops.loss_modules import UganDiscriminatorLoss, UganGeneratorLoss\n",
    "from stories import Failure, Success, arguments, story\n",
    "from stories.exceptions import FailureError\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from loguru import logger\n",
    "from torchvision.datasets.folder import ImageFolder\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UganTrainPipeline(object):\n",
    "   \n",
    "\n",
    "    @story\n",
    "    @arguments(\n",
    "        \"training_dataset_A_path\",\n",
    "        \"training_dataset_B_path\",\n",
    "        \"epochs_num\",\n",
    "        \"batch_size\",\n",
    "        \"num_critic\",\n",
    "        \"learning_rate\",\n",
    "        \"torch_manual_seed\",\n",
    "        \"epoch_save_period\",\n",
    "        \"save_discriminator_net\",\n",
    "        \"model_save_path_prefix\",\n",
    "    )\n",
    "    def run(I):  # noqa: WPS111, N805, N803\n",
    "        I.init  # noqa: WPS428\n",
    "        I.train  # noqa: WPS428\n",
    "\n",
    "    @story\n",
    "    @arguments(\n",
    "        \"training_dataset_A_path\",\n",
    "        \"training_dataset_B_path\",\n",
    "        \"batch_size\",\n",
    "        \"learning_rate\",\n",
    "        \"torch_manual_seed\",\n",
    "    )\n",
    "    def init(I):\n",
    "        I.init_torch_seed  # noqa: WPS428\n",
    "        I.init_tensorboard_writer  # noqa: WPS428\n",
    "        I.init_net_modules  # noqa: WPS428\n",
    "        I.init_loss_modules  # noqa: WPS428\n",
    "        I.choose_cuda_as_device_if_available  # noqa: WPS428\n",
    "        I.apply_dataparallel_if_multi_gpu  # noqa: WPS428\n",
    "        I.move_criterions_to_device  # noqa: WPS428\n",
    "        I.move_nets_to_device  # noqa: WPS428\n",
    "        I.init_optimizers  # noqa: WPS428\n",
    "        I.init_train_dataset  # noqa: WPS428\n",
    "        I.init_data_loader  # noqa: WPS428\n",
    "\n",
    "    def init_torch_seed(self, ctx):\n",
    "        torch.manual_seed(ctx.torch_manual_seed)\n",
    "        return Success()\n",
    "\n",
    "    def init_tensorboard_writer(self, ctx):\n",
    "        tensorboard_writer = SummaryWriter()\n",
    "        return Success(tensorboard_writer=tensorboard_writer)\n",
    "\n",
    "    def init_net_modules(self, ctx):\n",
    "        generator_net = pix2pix.GeneratorNet()\n",
    "        discriminator_net = pix2pix.DiscriminatorNet()\n",
    "        return Success(generator_net=generator_net, discriminator_net=discriminator_net)\n",
    "\n",
    "    def init_loss_modules(self, ctx):\n",
    "        criterion_for_generator = UganGeneratorLoss(ctx.tensorboard_writer)\n",
    "        criterion_for_discriminator = UganDiscriminatorLoss(ctx.tensorboard_writer)\n",
    "        return Success(\n",
    "            criterion_for_generator=criterion_for_generator,\n",
    "            criterion_for_discriminator=criterion_for_discriminator,\n",
    "        )\n",
    "\n",
    "    def choose_cuda_as_device_if_available(self, ctx):\n",
    "        device_type = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        device = torch.device(device_type)\n",
    "        if device_type == \"cpu\":\n",
    "            logger.info(\"Cuda will not be used for training!\")\n",
    "        else:\n",
    "            logger.info(\"{} will be used for training!\", device)\n",
    "        return Success(device=device)\n",
    "\n",
    "    def apply_dataparallel_if_multi_gpu(self, ctx):\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            logger.info(\"Let's use \", torch.cuda.device_count(), \" GPUs!\")\n",
    "            ctx.criterion_for_generator = torch.nn.DataParallel(\n",
    "                ctx.criterion_for_generator\n",
    "            )\n",
    "            ctx.criterion_for_discriminator = torch.nn.DataParallel(\n",
    "                ctx.criterion_for_discriminator\n",
    "            )\n",
    "        return Success()\n",
    "\n",
    "    def move_criterions_to_device(self, ctx):\n",
    "        ctx.criterion_for_generator.to(ctx.device)\n",
    "        ctx.criterion_for_discriminator.to(ctx.device)\n",
    "        return Success()\n",
    "\n",
    "    def move_nets_to_device(self, ctx):\n",
    "        ctx.generator_net.to(ctx.device)\n",
    "        ctx.discriminator_net.to(ctx.device)\n",
    "        return Success()\n",
    "\n",
    "    def init_optimizers(self, ctx):\n",
    "        generator_net_optimizer = torch.optim.Adam(\n",
    "            ctx.generator_net.parameters(), lr=ctx.learning_rate\n",
    "        )\n",
    "        discriminator_net_optimizer = torch.optim.Adam(\n",
    "            ctx.discriminator_net.parameters(), lr=ctx.learning_rate\n",
    "        )\n",
    "        return Success(\n",
    "            generator_net_optimizer=generator_net_optimizer,\n",
    "            discriminator_net_optimizer=discriminator_net_optimizer,\n",
    "        )\n",
    "\n",
    "    def init_train_dataset(self, ctx):\n",
    "        transform_a = transforms.Compose([ToTensor()])\n",
    "        transform_b = transforms.Compose([ToTensor()])\n",
    "        training_dataset = UganTrainingDataset(\n",
    "            ctx.training_dataset_A_path,\n",
    "            ctx.training_dataset_B_path,\n",
    "            transform_a=transform_a,\n",
    "            transform_b=transform_b,\n",
    "        )\n",
    "        if len(training_dataset) == 0:\n",
    "            return Failure(self.Errors.training_dataset_is_empty)\n",
    "        return Success(training_dataset=training_dataset)\n",
    "\n",
    "    def init_data_loader(self, ctx):\n",
    "        data_loader = DataLoader(\n",
    "            dataset=ctx.training_dataset, batch_size=ctx.batch_size, shuffle=True,\n",
    "        )\n",
    "        return Success(data_loader=data_loader)\n",
    "\n",
    "    def train(self, ctx):\n",
    "        # Training loop\n",
    "        logger.info(\"Start training loop...\")\n",
    "        iteration_index = 0\n",
    "        for epoch_index in range(ctx.epochs_num):\n",
    "            for sample_batch_a, sample_batch_b in ctx.data_loader:\n",
    "                sample_batch_a, sample_batch_b = self.load_batches_to_device(\n",
    "                    sample_batch_a, sample_batch_b, ctx.device\n",
    "                )\n",
    "                generated_images = ctx.generator_net(sample_batch_a)\n",
    "                for _index in range(ctx.num_critic):\n",
    "                    discriminator_loss = self.train_discriminator(\n",
    "                        sample_batch_a,\n",
    "                        sample_batch_b,\n",
    "                        generated_images,\n",
    "                        ctx,\n",
    "                        iteration_index,\n",
    "                    )\n",
    "                generator_loss = self.train_generator(\n",
    "                    sample_batch_b, generated_images, ctx, iteration_index\n",
    "                )\n",
    "                logger.info(\n",
    "                    \"Epoch {}, iteration {}, discriminator loss: {}, generator loss: {}\".format(\n",
    "                        epoch_index + 1,\n",
    "                        iteration_index + 1,\n",
    "                        discriminator_loss,\n",
    "                        generator_loss,\n",
    "                    )\n",
    "                )\n",
    "                iteration_index += 1\n",
    "            self.checkpoint(ctx, epoch_index)\n",
    "        return Success()\n",
    "\n",
    "    def load_batches_to_device(self, sample_batch_a, sample_batch_b, device):\n",
    "        return sample_batch_a.to(device), sample_batch_b.to(device)\n",
    "\n",
    "    def train_discriminator(\n",
    "        self, sample_batch_a, sample_batch_b, generated_images, ctx, iteration_index\n",
    "    ):\n",
    "        ctx.discriminator_net_optimizer.zero_grad()\n",
    "        discriminator_fake = ctx.discriminator_net(generated_images).to(ctx.device)\n",
    "        discriminator_correct = ctx.discriminator_net(sample_batch_a).to(ctx.device)\n",
    "        discriminator_loss = ctx.criterion_for_discriminator.forward(\n",
    "            discriminator_fake,\n",
    "            discriminator_correct,\n",
    "            sample_batch_b,\n",
    "            generated_images,\n",
    "            ctx.discriminator_net,\n",
    "            iteration_index,\n",
    "        )\n",
    "        discriminator_loss.backward(retain_graph=True)\n",
    "        ctx.generator_net.zero_grad()\n",
    "        ctx.discriminator_net_optimizer.step()\n",
    "        return discriminator_loss.item()\n",
    "\n",
    "    def train_generator(self, sample_batch_b, generated_images, ctx, iteration_index):\n",
    "        ctx.generator_net_optimizer.zero_grad()\n",
    "        discriminator_fake = ctx.discriminator_net(generated_images)\n",
    "        generator_loss = ctx.criterion_for_generator(\n",
    "            discriminator_fake, sample_batch_b, generated_images, iteration_index\n",
    "        )\n",
    "        generator_loss.backward()\n",
    "        ctx.discriminator_net.zero_grad()\n",
    "        ctx.generator_net_optimizer.step()\n",
    "        return generator_loss.item()\n",
    "\n",
    "    def checkpoint(self, ctx, epoch_index):\n",
    "        if (\n",
    "            epoch_index + 1\n",
    "        ) % ctx.epoch_save_period == 0 or epoch_index + 1 == ctx.epochs_num:\n",
    "            # Make sample input for tracing\n",
    "            sample_size = ctx.training_dataset[0][0].shape\n",
    "            sample_size = (1, *sample_size)\n",
    "            sample_input = torch.rand(sample_size).to(ctx.device)\n",
    "            generator_trace = torch.jit.trace(ctx.generator_net, sample_input)\n",
    "            generator_trace_filepath = (\n",
    "                ctx.model_save_path_prefix\n",
    "                + \"_generator_epoch{}.pt\".format(epoch_index + 1)\n",
    "            )\n",
    "            logger.info(\"Saving generator trace at {}\".format(generator_trace_filepath))\n",
    "            torch.jit.save(generator_trace, generator_trace_filepath)\n",
    "            if ctx.save_discriminator_net:\n",
    "                discriminator_trace_filepath = (\n",
    "                    ctx.model_save_path_prefix\n",
    "                    + \"_discriminator_epoch{}.pt\".format(epoch_index + 1)\n",
    "                )\n",
    "                logger.info(\n",
    "                    \"Saving discriminator trace at {}\".format(\n",
    "                        discriminator_trace_filepath\n",
    "                    )\n",
    "                )\n",
    "                discriminator_trace = torch.jit.trace(\n",
    "                    ctx.discriminator_net, sample_input\n",
    "                )\n",
    "                torch.jit.save(discriminator_trace, discriminator_trace_filepath)\n",
    "\n",
    "    @init.failures\n",
    "    class Errors(Enum):\n",
    "        training_dataset_is_empty = auto()\n",
    "\n",
    "\n",
    "class UganDatasetInferencePipeline(object):\n",
    "    \"\"\"\n",
    "    Simple pipeline for inferencing data from dataset and model trace\n",
    "    It is made as a @story with context ctx, same as UganTrainPipeline\n",
    "    \"\"\"\n",
    "\n",
    "    @story\n",
    "    @arguments(\n",
    "        \"target_dataset_path\",\n",
    "        \"trace_filepath\",\n",
    "        \"output_directory_path\",\n",
    "        \"batch_size\",\n",
    "        \"torch_manual_seed\",\n",
    "        \"use_cuda\",\n",
    "    )\n",
    "    def run(I):  # noqa: WPS111, N805, N803\n",
    "        I.init  # noqa: WPS428\n",
    "        I.inference  # noqa: WPS428\n",
    "\n",
    "    @story\n",
    "    @arguments(\n",
    "        \"target_dataset_path\",\n",
    "        \"trace_filepath\",\n",
    "        \"batch_size\",\n",
    "        \"torch_manual_seed\",\n",
    "        \"use_cuda\",\n",
    "    )\n",
    "    def init(I):\n",
    "        I.init_torch_seed  # noqa: WPS428\n",
    "        I.init_generator_net_module  # noqa: WPS428\n",
    "        I.choose_cuda_as_device_if_available  # noqa: WPS428\n",
    "        I.move_generator_net_to_device  # noqa: WPS428\n",
    "        I.init_target_dataset  # noqa: WPS428\n",
    "        I.init_data_loader  # noqa: WPS428\n",
    "\n",
    "    def init_torch_seed(self, ctx):\n",
    "        torch.manual_seed(ctx.torch_manual_seed)\n",
    "        return Success()\n",
    "\n",
    "    def init_generator_net_module(self, ctx):\n",
    "        generator = torch.jit.load(ctx.trace_filepath)\n",
    "        return Success(generator=generator)\n",
    "\n",
    "    def choose_cuda_as_device_if_available(self, ctx):\n",
    "        device_type = \"cuda\" if torch.cuda.is_available() and ctx.use_cuda else \"cpu\"\n",
    "        device = torch.device(device_type)\n",
    "        if device_type == \"cpu\":\n",
    "            logger.info(\"Cuda will not be used for inference!\")\n",
    "        else:\n",
    "            logger.info(\"{} will be used for inference!\", device)\n",
    "        return Success(device=device)\n",
    "\n",
    "    def move_generator_net_to_device(self, ctx):\n",
    "        ctx.generator.to(ctx.device)\n",
    "        return Success()\n",
    "\n",
    "    def init_target_dataset(self, ctx):\n",
    "        target_dataset = UganInferenceDataset(\n",
    "            ctx.target_dataset_path, transform=transforms.Compose([ToTensor()])\n",
    "        )\n",
    "        if len(target_dataset) == 0:\n",
    "            return Failure(self.Errors.target_dataset_is_empty)\n",
    "        return Success(target_dataset=target_dataset)\n",
    "\n",
    "    def init_data_loader(self, ctx):\n",
    "        data_loader = DataLoader(\n",
    "            dataset=ctx.target_dataset, batch_size=ctx.batch_size, shuffle=False,\n",
    "        )\n",
    "        return Success(data_loader=data_loader)\n",
    "\n",
    "    def inference(self, ctx):\n",
    "        num_of_batches = math.ceil(len(ctx.target_dataset) / ctx.batch_size)\n",
    "        with torch.no_grad():\n",
    "            for index, data_batch in enumerate(ctx.data_loader):\n",
    "                logger.info(\n",
    "                    \"Inferencing batch {} out of {} batches({:.2f}%)\".format(\n",
    "                        index + 1, num_of_batches, 100 * (index + 1) / num_of_batches\n",
    "                    )\n",
    "                )\n",
    "                filenames = [os.path.basename(filepath) for filepath in data_batch[0]]\n",
    "                image_batch = data_batch[1].to(ctx.device)\n",
    "                output_batch_tensor = ctx.generator.forward(image_batch)\n",
    "                logger.info(output_batch_tensor)\n",
    "                output_images = self.save_batch_to_folder(\n",
    "                    output_batch_tensor, filenames, ctx.output_directory_path\n",
    "                )\n",
    "        return Success()\n",
    "\n",
    "    def save_batch_to_folder(self, images_tensor, filenames, output_directory_path):\n",
    "        for index, image_name in enumerate(filenames):\n",
    "            save_path = output_directory_path + image_name\n",
    "            image = numpy.asarray(\n",
    "                images_tensor[index].cpu().detach().permute(1, 2, 0).numpy().clip(0, 1)\n",
    "            )\n",
    "            matplotlib.pyplot.imsave(save_path, image)\n",
    "        return Success()\n",
    "\n",
    "    @init.failures\n",
    "    class Errors(Enum):\n",
    "        target_dataset_is_empty = auto()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
